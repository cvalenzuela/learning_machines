{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from random import shuffle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data length: 32562\n",
      "(26049, 16)\n",
      "(26049,)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "# https://archive.ics.uci.edu/ml/datasets/Adult\n",
    "with open('data/adults.txt', 'r') as f:\n",
    "    data = list(csv.reader(f))\n",
    "    print('Total data length:', len(data))\n",
    "\n",
    "columns = ['age','workclass','fnlwgt','education','educationnum','maritalstatus','occupation','relationship','race','sex','capitalgain','capitalloss','hoursperweek','country','income']\n",
    "\n",
    "# clean and replace >50K with 1 and <50K with 0\n",
    "data = [x for x in data if len(x) == 15]\n",
    "for element in data:\n",
    "    for i in range(len(element)):\n",
    "        element[i] = element[i].replace(\" \", \"\")\n",
    "        if(i == 14):\n",
    "            if(element[i] == '>50K'):\n",
    "                element[i] = 1\n",
    "            else:\n",
    "                element[i] = 0\n",
    "\n",
    "#shuffle the data\n",
    "shuffle(data)\n",
    "\n",
    "# set training and test sizes\n",
    "training_size = int(len(data)*0.8)\n",
    "\n",
    "# Input: education | output: income\n",
    "# set training and test data \n",
    "training_data = [[x[3], x[4], x[14]] for x in data[:training_size + 1]]\n",
    "test_data = [[x[3], x[4], x[14]] for x in data[training_size:]]\n",
    "\n",
    "education_unique_values = list({x[0] for x in training_data})\n",
    "education_years_unique_values = list({x[1] for x in training_data})\n",
    "\n",
    "# one-hot encode for education level\n",
    "for obs in training_data:\n",
    "    onehot = [0] * len(education_unique_values)\n",
    "    onehot[education_unique_values.index(obs[0])] = 1\n",
    "    obs[0] = onehot\n",
    "\n",
    "# one-hot decode\n",
    "def decode(value):\n",
    "    for i in range(len(value[0])):\n",
    "        if(value[0][i] == 1.0):\n",
    "            return education_unique_values[int(i)]\n",
    "        \n",
    "# Set training inputs and outputs\n",
    "training_inputs = []\n",
    "for i in training_data:\n",
    "    training_inputs.append(i[0])\n",
    "    \n",
    "training_outputs = []\n",
    "for i in training_data:\n",
    "    training_outputs.append(i[2])\n",
    "\n",
    "training_inputs = np.array(training_inputs)\n",
    "training_outputs = np.array(training_outputs)\n",
    "print(training_inputs.shape)\n",
    "print(training_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Activation function definitions:\n",
    "def sigmoid_fn(x):\n",
    "    return 1.0 / ( 1.0 + np.exp( -x ) )\n",
    "\n",
    "def sigmoid_dfn(x):\n",
    "    y = sigmoid_fn( x )\n",
    "    return y * ( 1.0 - y )\n",
    "\n",
    "def tanh_fn(x):\n",
    "    return np.sinh( x ) / np.cosh( x )\n",
    "\n",
    "def tanh_dfn(x):\n",
    "    return 1.0 - np.power( tanh_fn( x ), 2.0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# MLP Layer Class:\n",
    "class MlpLayer:\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.rand( output_size, input_size ) * 2.0 - 1.0\n",
    "        self.bias    = np.zeros( ( output_size, 1 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# MLP Class:\n",
    "class Mlp:\n",
    "    def __init__(self,layer_sizes,activation_fn_name):\n",
    "        # Create layers:\n",
    "        self.layers = []\n",
    "        for i in range( len( layer_sizes ) - 1 ):\n",
    "            self.layers.append( MlpLayer( layer_sizes[ i ], layer_sizes[ i + 1 ] ) )\n",
    "        # Set activation function:\n",
    "        if activation_fn_name == \"tanh\":\n",
    "            self.activation_fn  = tanh_fn\n",
    "            self.activation_dfn = tanh_dfn\n",
    "        else:\n",
    "            self.activation_fn  = sigmoid_fn\n",
    "            self.activation_dfn = sigmoid_dfn\n",
    "\n",
    "    def predictSignal(self,input):\n",
    "        # Setup signals:\n",
    "        activations = [ input ]\n",
    "        outputs     = [ input ]\n",
    "        # Feed forward through layers:\n",
    "        for i in range( 1, len( self.layers ) + 1 ):\n",
    "            # Compute activations:\n",
    "            curr_act = np.dot( self.layers[ i - 1 ].weights, outputs[ i - 1 ] ) + self.layers[ i - 1 ].bias\n",
    "            # Append current signals:\n",
    "            activations.append( curr_act )\n",
    "            outputs.append( self.activation_fn( curr_act ) )\n",
    "        # Return signals:\n",
    "        return activations, outputs\n",
    "\n",
    "    def predict(self,input):\n",
    "        # Feed forward:\n",
    "        activations, outputs = self.predictSignal( input )\n",
    "        # Return final layer output:\n",
    "        return outputs[ -1 ]\n",
    "\n",
    "    def trainEpoch(self,input,target,learn_rate):\n",
    "        num_outdims  = target.shape[ 0 ]\n",
    "        num_examples = target.shape[ 1 ]\n",
    "        # Feed forward:\n",
    "        activations, outputs = self.predictSignal( input )\n",
    "        # Setup deltas:\n",
    "        deltas = []\n",
    "        count  = len( self.layers )\n",
    "        # Back propagate from final outputs:\n",
    "        deltas.append( self.activation_dfn( activations[ count ] ) * ( outputs[ count ] - target ) )\n",
    "        # Back propagate remaining layers:\n",
    "        for i in range( count - 1, 0, -1 ):\n",
    "            deltas.append( self.activation_dfn( activations[ i ] ) * np.dot( self.layers[ i ].weights.T, deltas[ -1 ] ) )\n",
    "        # Compute batch multiplier:\n",
    "        batch_mult = learn_rate * ( 1.0 / float( num_examples ) )\n",
    "        # Apply deltas:\n",
    "        for i in range( count ):\n",
    "            self.layers[ i ].weights -= batch_mult * np.dot( deltas[ count - i - 1 ], outputs[ i ].T )\n",
    "            self.layers[ i ].bias    -= batch_mult * np.expand_dims( np.sum( deltas[ count - i - 1 ], axis=1 ), axis=1 )\n",
    "        # Return error rate:\n",
    "        return ( np.sum( np.absolute( target - outputs[ -1 ] ) ) / num_examples / num_outdims )\n",
    "\n",
    "    def train(self,input,target,learn_rate,epochs,batch_size = 10,report_freq = 10):\n",
    "        num_examples = target.shape[ 1 ]\n",
    "        # Iterate over each training epoch:\n",
    "        for epoch in range( epochs ):\n",
    "            error = 0.0\n",
    "            # Iterate over each training batch:\n",
    "            for start in range( 0, num_examples, batch_size ):\n",
    "                # Compute batch stop index:\n",
    "                stop = min( start + batch_size, num_examples )\n",
    "                # Perform training epoch on batch:\n",
    "                batch_error = self.trainEpoch( input[ :, start:stop ], target[ :, start:stop ], learn_rate )\n",
    "                # Add scaled batch error to total error:\n",
    "                error += batch_error * ( float( stop - start ) / float( num_examples ) )\n",
    "            # Report error, if applicable:\n",
    "            if epoch % report_freq == 0:\n",
    "                # Print report:\n",
    "                print(\"Epoch: %d\\nError: %f\\n\" % ( epoch, error ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# MLP Visualization Class:\n",
    "class MlpVisualizer:\n",
    "    def __init__(self,data_xmin,data_xmax,data_ymin,data_ymax,report_freq,buffer_size = 100):\n",
    "        self.report_freq  = report_freq\n",
    "        self.error_buffer = buffer_size\n",
    "        # Setup plotter data:\n",
    "        self.error_xdata = []\n",
    "        self.error_ydata = []\n",
    "        # Setup plotter:\n",
    "        plt.ion()\n",
    "        self.fig = plt.figure( 1 )\n",
    "        self.fig.subplots_adjust( hspace = 0.3 )\n",
    "        # Add subplots:\n",
    "        self.datav_plot = self.fig.add_subplot( 2, 1, 1 )\n",
    "        self.error_plot = self.fig.add_subplot( 2, 1, 2 )\n",
    "        # Setup predictions subplot:\n",
    "        self.datav_plot.set_title( 'Predictions' )\n",
    "        self.datav_targ_line = Line2D( [], [], color='green', marker='+', linestyle='None' )\n",
    "        self.datav_pred_line = Line2D( [], [], color='red', marker='x', linestyle='None' )\n",
    "        self.datav_plot.add_line( self.datav_targ_line )\n",
    "        self.datav_plot.add_line( self.datav_pred_line )\n",
    "        self.datav_plot.set_xlim( data_xmin, data_xmax )\n",
    "        self.datav_plot.set_ylim( data_ymin, data_ymax )\n",
    "        # Setup error rate subplot:\n",
    "        self.error_plot.set_xlabel( 'Epoch' )\n",
    "        self.error_plot.set_ylabel( 'Error' )\n",
    "        self.error_line = Line2D( [], [], color='black' )\n",
    "        self.error_plot.add_line( self.error_line )\n",
    "        self.error_plot.set_ylim( 0.0, 1.0 )\n",
    "        # Show plot:\n",
    "        plt.show()\n",
    "\n",
    "    def saveImage(self,filepath):\n",
    "        plt.savefig( filepath )\n",
    "\n",
    "    def update(self,epoch,error,input,target,output):\n",
    "        # Update error plotter data:\n",
    "        if len( self.error_xdata ) == self.error_buffer:\n",
    "            self.error_xdata.pop( 0 )\n",
    "            self.error_ydata.pop( 0 )\n",
    "        self.error_xdata.append( epoch )\n",
    "        self.error_ydata.append( error )\n",
    "        #\n",
    "        title = 'Epoch: %d, Error: %f' % ( epoch, error )\n",
    "        self.error_plot.set_title( title )\n",
    "        # Compute error plotter x-range:\n",
    "        mlen = self.report_freq * self.error_buffer\n",
    "        xmin = np.amin( self.error_xdata )\n",
    "        xmax = max( xmin + mlen, np.amax( self.error_xdata ) )\n",
    "        # Update error plotter:\n",
    "        self.error_line.set_data( self.error_xdata, self.error_ydata )\n",
    "        self.error_plot.set_xlim( xmin, xmax )\n",
    "        # Update predictions plotter:\n",
    "        self.datav_targ_line.set_data( input, target )\n",
    "        self.datav_pred_line.set_data( input, output )\n",
    "        # Draw plot:\n",
    "        plt.draw()\n",
    "        plt.pause( 0.01 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-396-1f8049164a5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Train MLP:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtraining_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_cnt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_freq\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Make predictions:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-394-708bc7879980>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input, target, learn_rate, epochs, batch_size, report_freq)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearn_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreport_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mnum_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Iterate over each training epoch:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# Usage Example:\n",
    "\n",
    "# Set hyperparameters:\n",
    "sample_size = 1\n",
    "output_size = 1\n",
    "example_cnt = 300\n",
    "batch_size  = 10\n",
    "epoch_cnt   = 100\n",
    "report_freq = 10\n",
    "learn_rate  = 0.05\n",
    "\n",
    "# Construct MLP:\n",
    "mlp = Mlp( [ sample_size, 15, output_size ], \"tanh\" )\n",
    "\n",
    "# Construct dataset:\n",
    "#training_inputs  = np.random.uniform( 0.0, np.pi * 2.0, ( sample_size, example_cnt ) )\n",
    "#training_outputs = np.sin( training_inputs )\n",
    "\n",
    "# Train MLP:\n",
    "mlp.train( training_inputs, training_outputs, learn_rate, epoch_cnt, batch_size, report_freq )\n",
    "\n",
    "# Make predictions:\n",
    "#training_guesses = mlp.predict( training_inputs )\n",
    "\n",
    "# Print correct and predicted outputs:\n",
    "#print(( \"Outputs: %s\\nGuesses: %s\\n\" ) % ( training_outputs, training_guesses ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
